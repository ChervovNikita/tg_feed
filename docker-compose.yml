version: '3.8'

x-common-env: &common-env
  POSTGRES_USER: ${POSTGRES_USER:-postgres}
  POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
  POSTGRES_DB: ${POSTGRES_DB:-tg_filter}
  POSTGRES_HOST: postgres
  POSTGRES_PORT: 5432
  DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-tg_filter}
  KAFKA_BOOTSTRAP_SERVERS: kafka:9092

services:
  # ============ INFRASTRUCTURE ============
  
  postgres:
    image: pgvector/pgvector:pg16
    container_name: tg_filter_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-tg_filter}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-tg_filter}"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - tg_filter_network

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: tg_filter_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    networks:
      - tg_filter_network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: tg_filter_kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      - tg_filter_network

  kafka-init:
    image: confluentinc/cp-kafka:7.5.0
    container_name: tg_filter_kafka_init
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      echo 'Creating Kafka topics...'
      kafka-topics --create --if-not-exists --topic raw_posts --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1
      kafka-topics --create --if-not-exists --topic filtered_posts --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1
      kafka-topics --create --if-not-exists --topic reactions --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1
      echo 'Topics created successfully!'
      kafka-topics --list --bootstrap-server kafka:9092
      "
    networks:
      - tg_filter_network

  # ============ ML SERVICE ============
  
  ml-service:
    build:
      context: ./services/ml_service
      dockerfile: Dockerfile
    container_name: tg_filter_ml_service
    environment:
      <<: *common-env
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - tg_filter_network
    restart: unless-stopped

  # ============ MEDIUM SCRAPER ============
  
  medium-scraper:
    build:
      context: ./services/medium_scraper
      dockerfile: Dockerfile
    container_name: tg_filter_medium_scraper
    environment:
      <<: *common-env
      MEDIUM_TAGS: ${MEDIUM_TAGS:-programming,technology,software-development}
      MEDIUM_COOKIE: ${MEDIUM_COOKIE:-}
      POLL_INTERVAL_SECONDS: ${POLL_INTERVAL_SECONDS:-60}
      MIN_ARTICLE_LENGTH: ${MIN_ARTICLE_LENGTH:-500}
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - tg_filter_network
    restart: unless-stopped

  # ============ TELEGRAM BOT ============
  
  bot:
    build:
      context: ./services/bot
      dockerfile: Dockerfile
    container_name: tg_filter_bot
    environment:
      <<: *common-env
      BOT_TOKEN: ${BOT_TOKEN}
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      ml-service:
        condition: service_healthy
    networks:
      - tg_filter_network
    restart: unless-stopped

  # ============ ANALYTICS UI ============
  
  streamlit:
    build:
      context: ./services/streamlit
      dockerfile: Dockerfile
    container_name: tg_filter_streamlit
    environment:
      <<: *common-env
    ports:
      - "8501:8501"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - tg_filter_network
    restart: unless-stopped

  # ============ MONITORING ============
  
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: tg_filter_prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    networks:
      - tg_filter_network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:10.2.0
    container_name: tg_filter_grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GF_SECURITY_ADMIN_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
      - postgres
    networks:
      - tg_filter_network
    restart: unless-stopped

  # ============ AIRFLOW ============
  
  airflow-init:
    image: apache/airflow:2.8.0-python3.11
    container_name: tg_filter_airflow_init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY:-}
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./requirements/airflow.txt:/requirements.txt
    entrypoint: /bin/bash
    command:
      - -c
      - |
        pip install -r /requirements.txt
        airflow db migrate
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - tg_filter_network

  airflow-webserver:
    image: apache/airflow:2.8.0-python3.11
    container_name: tg_filter_airflow_webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY:-}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY:-secret}
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-tg_filter}
      ML_SERVICE_URL: http://ml-service:8000
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./requirements/airflow.txt:/requirements.txt
    entrypoint: /bin/bash
    command:
      - -c
      - |
        pip install -r /requirements.txt
        rm -f /opt/airflow/airflow-webserver.pid
        airflow webserver
    ports:
      - "8080:8080"
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    networks:
      - tg_filter_network
    restart: unless-stopped

  airflow-scheduler:
    image: apache/airflow:2.8.0-python3.11
    container_name: tg_filter_airflow_scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY:-}
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-tg_filter}
      ML_SERVICE_URL: http://ml-service:8000
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./requirements/airflow.txt:/requirements.txt
    entrypoint: /bin/bash
    command:
      - -c
      - |
        pip install -r /requirements.txt
        rm -f /opt/airflow/airflow-scheduler.pid
        airflow scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    networks:
      - tg_filter_network
    restart: unless-stopped

volumes:
  postgres_data:
  zookeeper_data:
  kafka_data:
  prometheus_data:
  grafana_data:

networks:
  tg_filter_network:
    driver: bridge
